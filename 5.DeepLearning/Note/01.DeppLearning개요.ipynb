{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>머신러닝과 딥러닝의 차이점</b>     \n",
    ": 머신러닝은 사람 개입 딥러닝은 사람 개입 거의 없거나 없음   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;-Image (CNN)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;-문장(RNN)    \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 위의 기능만 딥러닝에서 특화되어있음   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "- 머신러닝의 한 종류.\n",
    "- 여러 층(은닉층)을 가진 신경망을 사용해 머신러닝을 수행하는 것. \n",
    "- 이미지 인식, 음성인식, 자연어 처리등의 다양한 분야에 활용\n",
    "- 1980년대부터 있었지만 현대에 와서 컴퓨터 성능이 좋아지고 비즈니스적으로 성공하면서 주목 받기 시작함.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning과 Machine Learning의 차이점\n",
    "- 가장 큰 차이점 Feature(특징량) 추출\n",
    "- Deep Learning은 스스로 학습을 하기 때문에 Machine Learning보다 많은 Data가 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트폰을 구매할까?\n",
    "- 구매의 경우는 y에 1\n",
    "- 그렇지 않는 경우는 y에 0\n",
    "\n",
    "입력의 요인들 정리\n",
    "- X1: 이번달의 수입은 충분한가?\n",
    "- X2: 최신 기능을 가지고 있는가?\n",
    "- X3: 기존의 스마트폰에 문제가 있는가?\n",
    "\n",
    "X1, X2, X3의 가중치를 w1, w2, w3로 하였을 때 예상되는 조건들은 다음과 같습니다.\n",
    "- 부자인 경우에는 w1=1, w2=8, w3=2         \n",
    "- 스마트폰에 문제가 생긴 사람의 가중치는 w1=2, w2=1, w3=8\n",
    "- 정기적으로 스마트폰을 구매한 사람의 가중치는 w1=1,w2=8, w3=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파(forward propagation)\n",
    "- 왼쪽에서 오는쪽으로 흘러가는 과정\n",
    "- 순전파에 의해 딥러닝의 출력값(y^)이 결정, wk은 (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수(Loss Function)\n",
    "- 출력값과 정답의 차이\n",
    "- 출력값과 정답이 일치할수록 손실함수의 값은 적어진다.    \n",
    "- 회귀에서는 평균제곱오차(Mean Squared Error)\n",
    "- 분류에 크로스 엔트로피(Cross Entropy)를 사용\n",
    "- 매개 변수(w,b)를 조절해서 손실함수의 값을 최저로 만든는 과정을 최적화(Optimization)이라 한다.\n",
    "- 최적한 과정은 optimizer를 통해 이뤄지며 Optimizer는 역전파(back propagation)의 과정을 수행해서 딥러닝 모델의 매개변수를 최적화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화(Optimization)\n",
    "- 대표적인 방법은 경사하강법\n",
    "- 반복적으로 손실함수에 대한 모델 매개변수의 기울기를 구한후 그 미분값을 반대방향으로 매개변수를 조절해 나가면 결국에는 최저 손실함수에 도달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역전파(back propagation)\n",
    "- Optimizer는 손실함수의 값을 최소화하기 위해 역전파를 사용해 딥러닝 모델의 모든 매개변수를 변경한다.\n",
    "- 손실함수의 값을 최소화 한다는 것은 정답과 예측값의 차이를 최소화 한다는 것이며 에러율을 최저로 줄인다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝의 과대적합(Overfitting)\n",
    "### 드롭 아웃(drop out)\n",
    "- 매개변수 중 일정량을 학습 중간마다 무작위로 사용하지 않는 방법 \n",
    "- 드롭아웃을 사용하면 모델에 앙상블 효과\n",
    "### 조기 종료(Early Stopping)\n",
    "- 무조건 학습 반복 횟수를 높이면 학습시간이 길어져서 학습데이트만 성능이 좋은 현상이 발생\n",
    "- 학습데이터로만 모델의 매개변수로 조정하고 검증데이터로 모델의 정확도를 측정한다.\n",
    "- 조기종료는 학습횟수에 따라 검증 정확도가 꾸준히 떨어지는 시점이 발견되면 그 즉시 학습을 중단하고 최고점을 사용한다는 개념"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
