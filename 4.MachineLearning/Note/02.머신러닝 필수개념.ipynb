{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지도학습과 비지도학습   \n",
    "- 학습 : 데이터를 특별한 알고리즘에 적용해 ML 모델을 정의된 문제에 최적화(가장 근접한 답을 내놓는 것) 시키는 과정      \n",
    "\n",
    "### 지도 학습(SL, Supervised Learning) \n",
    "- 비지도학습을 제외하곤 모두 지도학습(지도학습, 딥러닝, 강화학습..)     \n",
    "- 정답을 알려주면서 진행하는 학습       \n",
    "- 데이터의 원래 실제값 : 실제값, 정답, 레이블(label), 타겟(target), 클래스(class), y값 이라 표현      \n",
    "- ML 모델을 통해 예측한 값 : 예측값, 분류값, Y^(hat)이라 표현      \n",
    "- 지도학습의 예) 분류, 회귀가 대표적     \n",
    "\n",
    "\n",
    "### 비지도 학습(UL, Unsupervised Learning)\n",
    "- 정답(레이블) 없이 진행하는 학습     \n",
    "- 데이터 자체에서 패턴을 찾아내야 할 때 사용    \n",
    "- 비지도학습의 예) 군집화, 차원축소가 대표적        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 분류와 회귀 \n",
    "- 분류와 회귀의 큰 차이점은 데이터가 입력되었을 때 분류는 분리된 값(범주형)으로 예측, 회귀는 연속된 값(연속형)으로 예측      \n",
    "\n",
    "### 분류 (Classification)\n",
    "- 데이터가 입력되었을 때, 지도학습을 통해 미리 학습된 label 중 하나 또는 여러 개의 label로 예측     \n",
    "\n",
    "##### 이진분류 (binary classification)\n",
    "- 둘 중 하나의 값으로 분류하는 경우 (sigmoid 함수)             \n",
    "\n",
    "##### 다중분류 (multi classification)\n",
    "- 여러 개의 분류값 중 하나로 예측 (softmax 함수)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# 과대적합(overfitting) vs. 과소적합(underfitting)\n",
    "- 과대적합 : 필요 이상의 특징으로 학습하는 경우 (트레이닝 예측력 > 테스트 예측력)\n",
    "- 과소적합 : 데이터에서 충분히 특징을 찾아내지 못하고 ML 모델 학습을 할 경우 (트레이닝 예측력 < 테스트 예측력)\n",
    "\n",
    "### 과소적합 \n",
    "- 보통 테스트 데이터 뿐만 아니라 학습데이터에 대해서도 정확도 낮게 나올 경우, 과소적합 모델일 가능성이 높음    \n",
    "- 과소적합은 드문 일이고, 절대 사용하면 안된다. 차라리 과대적합에서 맞춰가는 게 낫다.\n",
    "\n",
    "### 과대적합 \n",
    "- 학습 데이터 외의 데이터에서 정확도가 낮게 나오는 모델(배운 건 잘하고 실전에 약한 경우)      \n",
    "- 데이터 특징들의 수치값을 정규화함으로써 특정 특징에 의한 편향(bias)을 줄이는 것이 과대적합을 피하는 좋은 \n",
    "방법 (*bias: y=ax+b에서 b)      \n",
    "- 딥러닝의 경우, 조기종료(early stopping), 드롭아웃(drop out)를 사용해 과대적합을 피할 수 있다.\n",
    "- 조기종료 : 트레이닝-검증 / 트레이닝-테스트의 격차가 멀어지면 학습을 멈추는 프로그램. 딥러닝은 어떤 컬럼을 쓰고, 말고 하는 개입이 없기 때문에 맨 처음엔 오차율이 매우 높다가 학습 할수록 낮아짐. 그런데 그 오차율이 내려가다가 올라가는 지점이 있는데, 그 지점이 오기 전에 끝내는 것이 조기 종료이다. 딥러닝에서 반복 횟수를 결정하는 건, 사람이 하는 게 아니고 이런 프로그래밍을 통해 가장 적합한 수로 결정한다.      \n",
    "- 드롭아웃 : 컬럼을 지우는 것      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 혼동행렬 (confusion matrix)\n",
    "- 모델의 성능을 평가할 때 사용하는 지표(예측값 - 실제값 정오표 테이블)             \n",
    "- 실제값과 예측값을 비교하여 실제값에 예측값이 얼마나 일치하는지 파악    \n",
    "- 모델의 성능은 혼동행렬에 기반한 단 하나의 수치로 표현 가능    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 모델의 성능 평가 \n",
    "- TP(True Positive) : 맞는 것을 올바르게 예측한 것 (a를 a라고 한 것)\n",
    "- TN(True Negative) : 틀린 것을 올바르게 예측한 것 (a 아닌 걸 a 아니라고 한 것 - a랑 관련 없는 것) \n",
    "- FP(False Positive) : 틀린 것을 맞다고 잘못 예측한 것 (a 아닌 걸 a라고 한 것)\n",
    "- FN(False Negative) : 맞는 것을 틀렸다고 잘못 예측한 것 (a를 a아니라고 한 것)\n",
    "\n",
    "#### 정확도 (Accuracy) \n",
    "- 가장 일반적인 모델 성능 평가 지표(정답률)   \n",
    "- 혼동행렬 상 TP를 전체 셀로 나눈 값(TP/ALL)에 해당 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 78.75%\n"
     ]
    }
   ],
   "source": [
    "print(f'정확도: {(9+15+24+15) / 80 * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델 정확도 : 69.0%\n",
      "B 모델 정확도 : 71.0%\n"
     ]
    }
   ],
   "source": [
    "# 두 모델의 정답률\n",
    "print(f'A 모델 정답률 : {(9+60) / 100 * 100}%')\n",
    "print(f'B 모델 정답률 : {(1+70) / 100 * 100}%')\n",
    "# - 정확도로는 비슷하기 때문에 성능평가가 어려움 -> 정밀도 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도 (Precision)\n",
    "- 각 모델들의 예측값이 얼마나 정확하게 예측되었는가를 나타내는 지표 \n",
    "- 타겟이라고 예측한 것들 중 진짜 타겟이 맞았던 것. (또는 다른 컬럼을 정해주든지)\n",
    "- 가장 높은 값이 1. 백분율 쓰지 않는다.      \n",
    "- 혼동행렬 상 TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델 암환자 정밀도 : 0.23076923076923078\n",
      "B 모델 암환자 정밀도 : 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "# 두 모델의 암환자에 대한 정밀도 \n",
    "# 암환자에 대한 정밀도니까 암환자라고 예측한 것에서 진짜 암환자인 것(정답 맞춘 것)이 정밀도! \n",
    "print(f'A 모델 암환자 정밀도 : { 9 / (9+30)}')\n",
    "print(f'B 모델 암환자 정밀도 : { 1 / (1+20)}')\n",
    "# - 암환자의 예측력 정밀도는 A모델이 더 우수하다. \n",
    "# - 일반환자에 대해서는 또 다를 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 재현율(Recall) \n",
    "- 실제값 중에서 모델이 검출한 실제값의 비율을 나타내는 지표  \n",
    "- 정답값에 대한 이야기. 실제 암환자 중에서 암환자로 예측한 것       \n",
    "- (cf.정밀도는 예측값에 대한 이야기였음. 암환자라고 예측한 것에서 암환자가 맞았던 것.)      \n",
    "- 혼동행렬 상 TP / (TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델 암환자 재현율 : 0.9\n",
      "B 모델 암환자 재현율 : 0.1\n"
     ]
    }
   ],
   "source": [
    "# 두 모델의 암환자에 대한 재현율 \n",
    "# 실제로 암환자인것들 중에서 암환자라고 예측한 것 \n",
    "print(f'A 모델 암환자 재현율 : { 9 / (9+1)}')\n",
    "print(f'B 모델 암환자 재현율 : { 1 / (1+9)}')\n",
    "# - 암환자 재현율은 A모델이 훨씬 우수하다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 점수(F1 Score)\n",
    "- 정밀도도 중요, 재현율도 중요. 어떤 것을 선택해야 할지 혼돈스러울 때, 두 값의 조화평균으로 수치화한 지표     \n",
    "- 조화평균 = 2 * a * b / (a + b)    \n",
    "- F1 score = 2 * 재현율 * 정밀도 / (재현율 + 정밀도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델 F1 Score : 0.3663716814159292\n",
      "B 모델 F1 Score : 0.06394557823129252\n"
     ]
    }
   ],
   "source": [
    "# 두 모델의 F1 Score 구하기 \n",
    "# - 지표는 3자리수까지 한다 \n",
    "print(f'A 모델 F1 Score : { 2 * 0.9 *0.230 / (0.9 + 0.230) }')\n",
    "print(f'B 모델 F1 Score : { 2* 0.1 * 0.047 / (0.1 + 0.047)}')\n",
    "# - A 모델의 F1 Score가 더 높다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# k-fold 교차 검증(k-fold cross validation)\n",
    "- 모든 학습 데이터를 한번씩 검증 데이터로 활용해 검증 데이터가 한쪽 데이터에 편향되지 않아 검증 데이터를 분리하지 않고도 학습 데이터에 대한 전반적인 검증 정확도를 구할 수 있음 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
